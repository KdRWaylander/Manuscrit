\chapter{Contexte}
	\par Dans ce chapitre, on aborde toute les notions préliminaires à un travail expérimental: la définition du sujet, les valeurs clefs, les méthodes de mesure. On établit également les objectifs que l'on cherchera à atteindre via expérimentation.
	
	\section{Définition et mesure des effets de la latence}
	\subsection{Définitions}	
	\par Il existe un certain nombre de définitions différentes de la latence. On a présenté notre approche dans la partie sur le score de réalisme. Indépendamment, les auteurs donnent souvent des définitions multiples. On présente ici deux définitions plutôt classiques de la latence (ou plutôt <<~des~>> latences) ainsi qu'une définition plus originale.
	
	\par La première définition est quadruple \citep{papadakis_system_2011}. La latence peut, selon ces auteurs, être définie telle que:
	\begin{itemize}
		\item le retard entre l'action d'un utilisateur et sa prise en compte par le système,
		\item le temps de calcul lié à l'application, typiquement la lourdeur des graphismes à afficher ou des algorithmes qui travaillent en arrière plan.
		\item le retard dû au temps mis pour afficher l'image calculée, qui est au minimum égal au taux de rafraichissement de l'écran,
		\item le retard engendré par la non-synchronisation écran - unité de calcul: une image calculée doit attendre le prochain rafraichissement de l'écran pour être affichée.
	\end{itemize}		
	
	\par D'autres auteurs, \citep{hale_handbook_2015}, proposent quand à eux une version différente, plus adaptée à la Réalité Virtuelle et à l'immersion. Ils définissent alors la latence comme:
	\begin{itemize}
		\item le retard entre un mouvement de l'utilisateur et la réponse du système de tracking (typiquement, l'envoie de l'information de la nouvelle position à l'ordinateur),
		\item le retard entre le mouvement de l'utilisateur et le même mouvement dans le programme,
		\item de manière générale, un temps de réponse retardé.
	\end{itemize}		
	
	\par On s'aperçoit que si la première définition est sensiblement la même que pour les auteurs précédents, les autres définitions ne convergent pas du tout. Il nous faut donc impérativement clairement définir le concept de latence que l'on utilise pour notre expérimentation. En l'occurrence, on choisit de se mettre dans le cadre deux la deuxième définition de \citep{hale_handbook_2015}: le retard entre le mouvement réel et le mouvement dans la simulation.
	
	\par Enfin, \citep{watson_effects_1998}, parle quant à lui non pas de latence directement mais d'un concept plus global: la réactivité du système, c'est à dire du temps qui s'écoule lorsque l'on effectue une action, pour recevoir un feedback. La réactivité du système se compose des éléments suivants: la latence en elle-même (sans plus de définition), le temps entre deux images affichées (l'inverse du taux de rafraichissement donc) ainsi que le délai entre l'action de l'utilisateur et le moment suivant où le système rafraichit les acquisitions. Typiquement, si le système de tracking capture les mouvements toutes les $100~ms$ mais que l'utilisateur commence son mouvement $20~ms$ après une capture, il y aura donc automatiquement un délai de $80~ms$ qui s'ajoutera, indépendamment du reste du système.
	
	\subsection{La performance comme outil de mesure}
	\par De nombreux auteurs ont travaillé sur l'influence de la latence. Afin de s'extraire le plus possible de la subjectivité humaine, il fallait trouver une méthode qui ne se repose sur aucun questionnaire, source de biais. L'approche utilisée est alors la performance à l'échelle d'une tâche à réaliser dans l'environnement virtuel. L'influence de la latence sur la performance a été traitée de nombreuse fois dans la littérature \citep{ellis_sensor_1999,mania_perceptual_2004,watson_effects_1998,papadakis_system_2011,meehan_effect_2003}., et il a été démontré que la performance varie de manière inverse par rapport à la latence: plus cette dernière augmente, plus la performance en est affectée. C'est notamment par le biais de la mesure de performance que nous mèneront notre expérimentation.
	
	\par Parallèlement, \citep{meehan_effect_2003} proposent un autre moyen d'établir l'influence de la latence, qui ne passe pas par la performance. Pour rester sur des facteurs objectifs, ils mesurent des facteurs biologiques dans le corps humain directement, tels que le rythme cardiaque et la conductance de la peau (qui augmente avec la transpiration). Avec ces mesures, ils démontrent également et de manière alternative là encore, que la latence a un effet sur la présence: plus la latence est faible, plus la présence est forte.
	
	\section{Perception de la latence}
	\subsection{Notions de psychométrie}
	\par L'étude de la littérature nécessite, au préalable, un petit détour par le domaine de la psychométrie et la définition d'un certain nombre de grandeurs que l'on sera amené à rencontrer. On se contentera ici d'une brève introduction pour la compréhension puisque l'on ne cherchera pas à monter une expérimentation purement psychométrique. Dans ce domaine, les ouvrages de référence restent le Manuel Pratique de Psychophysique de \citep{bonnet_manuel_1986} pour la langue française et Psychophysics: A Practical Introduction de \citep{kingdom_psychophysics:_2010} pour la langue anglaise.
	
	\par La psychométrie est l'étude quantitative de la relation entre un phénomène physique quantifiable et la ou les réponses générées par le système sensoriel humain. Elle permet d'établir des modèles de fonctionnement à plusieurs niveaux: la structure du stimulus, le fonctionnement perceptif, ou bien le/s processus d'élaboration des réponses sensorielles. La notion de stimulus est  définie chez \citep{bonnet_manuel_1986} telle que:
	\begin{quote}
		Ensemble des évènements physiques qui déclenchent l'activité des récepteurs sensoriels et étant ainsi à l'origine des réponses observées.
	\end{quote}
	
	\par Une notion fondamentale en psychométrie est celle de seuil, c'est à dire de limite établie entre deux états: l'état haut et l'état bas. Selon la tâche effectuée, l'état haut peut être une détection de stimulus, une discrimination, une reconnaissance, une identification, ... tandis que l'état bas sera toujours défini comme l'absence d'état haut. Trois hypothèses sont nécessaires à la reconnaissance d'un seuil:
	\begin{itemize}
		\item \textbf{Hypothèse 1:} il ne doit pas être attribué au stimulus de part dans la variation observée des réponses (c'est à dire que le stimulus est considéré comme parfait et le récepteur comme observant des lois de probabilité),
		\item \textbf{Hypothèse 2:} il est admis un continuum des états d'excitation en réponse (c'est à dire que le comportement du système sensoriel ne doit pas changer du tout au tout au passage du seuil),
		\item \textbf{Hypothèse 3:} il est admis l'existence d'un mécanisme de réponse qui peut être modélisé sous la forme d'une règle logique.
	\end{itemize}		
	
	\par On note plus particulièrement deux seuils caractéristiques qui nous intéressent: le seuil de détection et le seuil de discrimination. 
	
	\par Le premier, appelé seuil de détection ou <<~absolute threshold~>> en anglais, caractérise la détection du stimulus, c'est à dire la capacité du sujet à répondre sur la présence ou l'absence de ce dernier. Il est nécessaire mais non suffisant pour déterminer en entier un système sensoriel: il faudrait également pouvoir en estimer la limite supérieure. Cependant, et dans de nombreux cas, il est difficile de faire des mesures expérimentales au delà d'une certaine intensité de stimulus sans endommager le système sensoriel des sujets. Typiquement, une luminance trop forte détruirait les cellules de la rétine dans l'œil. Ces grandeurs dont on ne peut pas mesurer le seuil maximal sont appelées <<~métathétique~>> \citep{stevens_psychophysical_1957}.
	
	\par Le deuxième seuil caractéristique est celui de discrimination (ou JND en anglais pour <<~just noticeable difference~>>). Il quantifie la capacité du sujet à distinguer une présence ou une absence de différence entre deux stimuli. Tout système, physique ou biologique, peut être caractérisé d'une part par ses limites de fonctionnement mais aussi par son pouvoir de résolution, sa capacité à discriminer deux niveaux voisins de signaux qu'il traite.
	
	\par La psychométrie propose ensuite des paradigmes pour établir des protocoles expérimentaux et des méthodes pour traiter les résultats et en extraire des modèles (avec notamment l'usage des fonctions psychométriques). Néanmoins, nous n'avons pas eu recours à ces méthodes pendant nos expérimentations et le développer serait donc légèrement hors-cadre. On présente donc dans la section suivante les différents seuils et influences sur l'expérience utilisateur liés à la latence, décrits dans la littérature.
	
	\subsection{Dans la littérature}
	\par Il est tout d'abord à noter que la perception de la latence se ferait de manière indirecte \citep{adelstein_head_2003}: elle serait perçue non pas directement pas les systèmes sensoriels mais par son effet sur l'environnement. On parle alors d'une forme analogue d' <<~oscillopsie~>> \citep{allison_tolerance_2001}, c'est à dire que l'environnement semble bouger, flotter dans l'espace. On peut donc extrapoler que, plus l'environnement est immersif, plus la ressenti de la latence sera fort. La perception est également indépendante de la complexité de la scène \citep{mania_perceptual_2004}: que l'on soit dans un décors minimaliste avec quelques polygones ou une scène surchargée, si les deux scènes ont la même quantité de latence, le ressenti sera le même. Enfin, la latence ne suivrait pas la loi de Weber \citep{adelstein_head_2003} qui implique que le seuil de perception est proportionnel à la valeur de l'intensité du stimulus: on percevrai donc également la même variation de latence, quelle que soit la valeur initiale de celle-ci.
	
	\par Le seuil de perception, donc de capacité à dire si le stimulus est présent ou non, a été mesuré à hauteur d'un intervalle de $15$ à $18.6~ms$ \citep{regan_real-time_1999}. Néanmoins, ces valeurs ont été observées pour un environnement souvent non-immersif et, comme on a pu le voir au paragraphe précédent, ce dernier paramètre pourrait avoir une forte influence sur le résultat. De même, les résultats peuvent fortement varier suivant si la tâche demandée pendant l'expérimentation demande de se concentrer sur la perception de la latence ou de se concentrer sur une autre activité. Par ailleurs, \citep{brooks_whats_1999} estime le seuil de perception, pour les simulateurs de vol (donc sans concentration sur la latence elle-même), à une valeur de $50~ms$. Regan et al. estiment également que le retard spécifiquement imputable au calcul de l'image (sans prise en compte ni de l'acquisition du mouvement, ni de l'affichage) est perceptible à partir de $15 \pm 3~ms$.
	
	\par Le seuil de discrimination (capacité à distinguer une différence entre deux stimuli) quant à lui, est mesuré pour la main à une valeur comprise entre $15$ et $20~ms$ et monte à une valeur de $50~ms$ pour la tête \citep{ellis_sensor_1999}. De leur côté, \citep{adelstein_head_2003} et \citep{mania_perceptual_2004} proposent des valeurs pour le tracking de la tête plus proches des valeurs de Ellis pour le tracking de la main avec respectivement $13.6 \pm 0.6~ms$ ($Max = 24.6~ms$) et $9.1 \pm 1.6~ms$ de JND.
	
	\par Enfin, \citep{allison_tolerance_2001} font une remarque intéressante: plus le mouvement de la tête est rapide, plus la latence doit être faible. Ils proposent des valeurs assez élevées comme seuil de perception mais l'ordre de grandeur permet toutefois la comparaison: pour une rotation lente de la tête, une latence de $320~ms$ est acceptable, tandis que pour une rotation rapide, le seuil descend à $180~ms$. Ces valeurs correspondent bien à la théorie de perception indirecte de la latence: plus on bouge vite, plus l'environnement va <<~flotter~>> et donc plus la perception sera forte. Cela donne également des indices sur une stratégie à adopter: quand la latence augmente, il peut être bienvenu de ralentir ses mouvements.
	
	\section{Mesure de la latence}
	\par On a vu que la mesure de l'influence de la latence sur l'être humain se faisait généralement via un indice de performance sur une tâche donnée. Il faut également être capable de mesurer le plus précisément possible quel est le niveau de latence auquel la tâche s'effectue. Cette fois, la mesure ne peut être qu'objective puisqu'elle n'implique pas le sujet humain mais seulement le système directement. On trouve un certain nombre de techniques dans la littérature, que nous allons présenter ici brièvement (de manière non exhaustive).
	
	\par Une première méthode pour déterminer la latence d'un système est décrite chez  \citep{liang_temporal-spatial_1991} et implique l'utilisation d'un pendule, d'un pendule fixe, d'une caméra, d'un module de tracking (ici, <<~Isotrack~>>) et d'un écran de retour (Fig. \ref{fig:liang_pendulum}). La technique revient à faire osciller un pendule devant une base fixée verticalement (type fil à plomb). Un système de tracking est associé au pendule et affiche, via l'écran de retour, ses mesures horodatées de position du pendule. Avec une caméra placée dans l'axe des pendules on peut, en analysant la vidéo image par image, mesurer l'écart de temps entre l'image montrant l'alignement entre les deux pendules et la mesure indiquant effectivement que le pendule est aligné avec la référence fixe.
	
	\begin{figure}
		\centering
		\includegraphics[scale=.75]{Figures/LiangPendulum}
		\caption{Méthode du pendule pour le calcul de la latence.}{Image tirée de \citep{liang_temporal-spatial_1991}}
		\label{fig:liang_pendulum}
	\end{figure}
	
	\par \citep{jacoby_improved_1996} utilisent également un pendule mais sans traitement vidéo a posteriori qui peut être un facteur d'imprécisions si la fréquence de capture d'image est trop basse (on risque de ne pas avoir l'image qui montre l'alignement parfait mais celle avec quelques degrés de plus ou de moins). Dans ce protocole, un ordinateur affiche une scène d'environ 1000 polygones non texturés et est relié à un système émetteur-receveur infrarouge. Le pendule coupe le rayon infrarouge à un certain point de sa course, ce qui a pour effet d'envoyer un ordre vers l'ordinateur qui doit modifier la couleur de certains de ces polygones. Un photodétecteur surveille en permanence l'écran et envoie un signal en tension lorsqu'il détecte le changement de couleur sur l'écran. Le système infrarouge et le photodétecteur sont tous deux cablés sur un oscilloscope qui permet de mesurer avec précision le temps entre leurs signaux respectifs.
	
	\par Parallèlement, il existe d'autres techniques qui ont été mises au point et qui n'impliquent pas de pendule et de mouvement oscillatoire. \citep{swindells_system_2000} génèrent un mouvement cyclique et périodique à l'aide de la table tournante d'un lecteur de vinyles. Un patch de forme ronde est placé et tracké sur la table tournante. Son mouvement est reproduit dans une scène virtuelle (Fig. \ref{fig:swindells_phonograph}). L'écart angulaire est mesuré entre le disque réel et le disque virtuel via des prises photo ou vidéo. La vitesse de rotation étant fixée et connue, on peut alors déduire le temps de latence généré par le système.
	
	\begin{figure}
		\centering
		\includegraphics[scale=.75]{Figures/SwindellsPhonograph}
		\caption{Méthode de la table tournante pour le calcul de la latence.}{Image tirée de \citep{swindells_system_2000}. La position du disque physique est appliqué au disque dans la scène virtuelle. Les deux images sont superposées et on mesure l'écart angulaire entre les deux. A partir de la vitesse de rotation on peut remonter à la latence.}
		\label{fig:swindells_phonograph}
	\end{figure}
	
	\par \citep{steed_simple_2008} proposent une autre méthode de pendule tracké, annoncée plus simple que les précédentes. Une diode électroluminescente rouge est fixée à un pendule et trackée grâce à un système optique. Le mouvement de la diode rouge est reproduit en vert sur un écran placé derrière le pendule tandis qu'une caméra filme l'ensemble. A partir de la vidéo, on peut être en mesure de reproduire les sinusoïdes que décrivent les mouvements des diodes réelle et virtuelle et ainsi en déduire la latence du système en prenant le temps crête à crête.
	
	\par Si les méthodes décrites jusqu'à présent sont très abstraites par rapport au déroulement réel d'une application en VR, \citep{di_luca_new_2010} propose une technique adaptative: que ce soit pour des lunettes 3D, pour un objet quelconque ou pour un casque de Réalité Virtuelle. La méthode nécessite deux photodétecteurs: le premier placé sur l'objet à tracker et le second au niveau de l'écran qui servira à afficher l'image pour le sujet: dans le cas d'un casque, les deux photorécepteurs seront placés sur le même objet (mais à des positions différents) alors que dans le cas d'un CAVE, les photorécepteurs seront distants (l'un sur les lunettes, l'autre au niveau d'un écran). On affiche, devant le premier photorécepteur (celui sur l'objet tracké), l'image fixe d'un gradient lumineux (un dégradé du noir vers le blanc typiquement). Si on déplace l'objet tracké dans le sens du gradient, on pourra obtenir l'équivalent de sa <<~position~>> via la valeur de luminosité qu'il mesure. De l'autre côté, le deuxième photodétecteur est dirigé vers l'écran destiné à l'utilisateur, sur lequel on affiche une nuance de gris (uniforme sur tout l'écran) en fonction des informations de tracking que l'on reçoit. En comparant le temps auquel le photorécepteur passe devant une nuance de gris donnée (en se déplaçant le long du gradient) et le temps où l'écran de l'utilisateur affiche cette même nuance de gris, on obtient la latence globale du système.
	
	\begin{figure}
		\centering
		\includegraphics[scale=.65]{Figures/DiLucaGradient}
		\caption{Méthode des gradients pour le calcul de la latence.}{Le cadre rouge représente la zone réellement mesurée par le photorécepteur tandis que le grand cadre vert montre la couleur affichée par l'écran final, ce qui correspond à une <<~position~>> sur le gradient fixe représentée par le cadre vert en pointillés. La différence entre les deux petits cadres permet de calculer la latence du système.}
		\label{fig:di_luca_gradient}
	\end{figure}
	
	\par Néanmoins, les méthodes impliquant des pendules ont un défaut majeur: les 6 axes de mouvements sont autorisés, ce qui donne un mouvement avec une composante fondamentale et des petites composantes harmoniques. Ces dernières peuvent influer sur le résultat final en augmentant subrepticement l'amplitude du mouvement par rapport à la théorie. Pour minimiser ces effets indésirables, \citep{papadakis_system_2011} proposent donc une méthode similaire au plateau tournant, avec un un système limité à 3 degrés de liberté dont 2 fixés. Une rotation est générée avec un servo-moteur et contrôlée avec un encodeur, le tout relié à un oscilloscope. L'environnement virtuel lit les valeurs de l'encodeur et est programmé de telle manière que, lorsque certains seuils de rotation sont franchis, il affiche un changement graphique (un carré de couleur blanche devient noir et inversement). Une photodiode placée au niveau de l'écran surveille ce carré et renvoie un signal à l'oscilloscope en cas de changement. Le reste de la scène virtuelle est un environnement lourd en polygones (environ 140000) et soumis à des calculs de lumière complexes afin de se rapprocher des usages normaux. On relève enfin la mesure de la latence sur l'oscilloscope avec le temps entre le passage de seuil au niveau de l'encodeur, et le changement de couleur au niveau de la photodiode.
	
	\par Bien que, dans l'idéal et pour maximiser la précision dans les mesures, il faudrait utiliser un oscilloscope, nous utiliserons pour notre expérimentation une méthode par la vidéo semblable à celle proposée par \citep{steed_simple_2008}, pour mesurer la latence de nos propres systèmes ; la précision étant suffisante pour notre application (voir chapitre suivant).
	
	
\chapter{Mise en place du dispositif expérimental}
	\par On connait maintenant mieux le contexte de la latence dans la Réalité Virtuelle. On pourra donc utiliser ces connaissances pour la planification et la réalisation d'une expérimentation. Si on connait les seuils de perception et de discrimination de la latence, la variation de la performance n'est pas décrite: on sait simplement qu'elle est impactée par la latence. Il pourrait également être intéressant de se pencher sur la différence d'influence de la latence par rapport au système immersif en lui même. On fixe donc un certain nombre d'objectifs pour cette expérimentation:
	\begin{itemize}
		\item Développer un des critères prépondérant du modèle de score de réalisme.
		\item Observer l'influence de la latence sur la performance, en milieu immersif.
		\item Comparer entre deux moyens immersifs (un casque et un simulateur type CAVE).
		\item Déterminer un seuil au delà duquel l'expérience utilisateur devient trop impactée. 
	\end{itemize}
	
	\par On présente dans ce chapitre la mise en place de notre expérimentation: l'établissement du protocole pour les sujets, les techniques mises au point pour mener à bien les différentes modalités et les mesures préliminaires nécessaires au bon fonctionnement de la manipulation.
	
	\section{Tâche à effectuer}
	\par Les sujets étaient confrontés à une situation écologique, c'est à dire sensée représenter la vie <<~réelle~>>, et il leur était demandé de réaliser une tâche de tous les jours telle que regarder à des endroits précis dans le cockpit d'une voiture, pendant de courts laps de temps.
	
	\subsection{Moyens immersifs}	
	\par Un des objectifs de l'expérimentation étant de faire également une comparaison entre plusieurs moyens immersifs,	on fait passer nos sujets dans un casque de Réalité Virtuelle (un Oculus Rift) et dans un simulateur de type CAVE.
	
	\par Le CAVE est le même que pour les précédentes expérimentations: que ce soit pour le contraste et la luminance ou pour la conduite suivie de questionnaires. Les sujets sont donc assis dans un CAVE 4 faces à 1 mètre de distance de la face principale (avant). Les sujets n'étaient pas assis sur un siège de voiture comme dans nos autres expérimentations mais sur un siège normal. Ce changement est dû à plusieurs raisons: premièrement, aucune tâche de conduite n'était nécessaire, ensuite, pour garder la continuité avec la chaise de même format utilisée pendant les essais dans le casque, et enfin,  pour des facilités de manœuvre. Les sujets n'étaient donc équipés que des lunettes de stéréoscopie et d'une manette de jeu faisant office d'interface de contrôle. Du point de vue des performances graphiques, l'application utilisée pendant l'expérimentation tournait à une valeur constante de 60 images par seconde.
	
	\par La partie casque de Réalité Virtuelle s'appuyait sur un Oculus Rift de type CV1 (Commercial Version 1, voir Fig. \ref{fig:oculus_rift}). L'utilisation du casque se faisait assis à une table disposée dans un des coins du CAVE, hors de vue d'un sujet passant dans le simulateur. L'assise se faisait au moyen d'une chaise parfaitement identique à la première pour assurer une continuité entre les deux. La caméra de tracking était placée sur la table, cette dernière servant aussi pour la réponse aux différents questionnaires (voir ensuite). De cette manière, les sujets pouvaient enchainer les deux moyens immersifs sans coupure. En terme de performances, l'application était stabilisée à 90 images par seconde.
	
	\par L'environnement virtuel était commun au CAVE et au casque: le sujet était assis au volant d'une voiture (modèle <<~officiel~>> interne Renault), à l'arrêt dans un <<~paysage~>> constitué de l'intérieur des bâtiments de Renault. Le paysage était réalisé au moyen d'une photo 360 degrés pour un maximum de photo-réalisme et pour limiter le nombre de triangles à afficher dans la scène (déjà bien chargée par le modèle de la voiture). Les lumières et réflexions des miroirs étaient pré-calculées pour limiter au maximum l'impact sur le temps de calcul des images.
	
	\begin{figure}
		\centering
		\includegraphics[scale=.65]{Figures/OculusRift}
		\caption{Oculus Rift et ses accessoires.}{De gauche à droite: la caméra permettant de tracker le casque, le casque vu de face (version CV1) et la manette de Xbox associée.}
		\label{fig:oculus_rift}
	\end{figure}
	
	\subsection{Détail de la tâche}	
	\par Une fois correctement installés dans l'environnement immersif, derrière de volant virtuel, les sujets pouvaient déclencher le début de la séquence de mesure. Il leur était alors demandé de viser visuellement des endroits précis (des <<~cibles~>>) dans la voiture, dans un ordre aléatoire, aussi rapidement et précisément que possible. La visée était aidée avec un réticule semblable à ce qui se fait dans les jeux vidéo, attaché au mouvement de la tête (voir le viseur rouge, Fig. \ref{fig:apparatus_latency}). Les cibles à viser étaient indiquée par une flèche blanche pointant une direction parmi 4 possibles (à gauche, à droite, en haut et en bas). Chaque direction de la flèche était associée à une cible: vers la gauche pour le rétroviseur gauche, vers la droite pour le rétroviseur droit, vers le haut pour le rétroviseur central et vers le bas pour la console centrale (l'écran tactile), voir Fig. \ref{fig:apparatus_latency}.
	
	\par Aussitôt que les sujets estimaient être au centre de la cible désignée, ils devaient appuyer sur un bouton (toujours le même) sur une manette de jeu (voir Fig. \ref{fig:oculus_rift}) qu'ils tenaient entre leurs mains. Chaque séquence dans le casque ou dans le CAVE était composée de 24 cibles à viser successivement (6 fois chacune des 4 cibles, mélangé aléatoirement). Les sujets devaient replacer leur réticule (et par conséquent la position de leur tête) à une position neutre après chaque visée: à l'endroit d'apparition de la flèche blanche.
	
	\par A chaque fois que les sujets appuyaient sur la manette et qu'ils étaient (par la biais du réticule) dans la cible désignée, le programme déclenchait une série de mesures (temps de passage, précision sur les axes vertical et horizontal, ...) qui sont décrites plus précisément dans la section suivante. Dans le cas d'un appui sur la manette sans cible désignée, en dehors de toute cible ou sur la mauvaise cible, rien ne se passait.
	
	\begin{figure}
		\centering
		\includegraphics[scale=.9]{Figures/ExpeLatency}
		\caption{Environnement virtuel pour l'expérimentation sur la latence.}{L'image est tirée du point de vue du sujet, la flèche blanche indique la cible à viser (ici, le rétroviseur gauche) tandis que la croix rouge (le viseur) est alignée avec la direction de la tête.}
		\label{fig:apparatus_latency}
	\end{figure}
	
	\par La même séquence de 24 cibles (avec néanmoins un ordre différent puisque celui-ci était tiré aléatoirement au début de chaque séquence) était répétée 6 fois: 4 fois dans le casque et 2 fois dans le CAVE. Là encore, l'ordre de passage était mélangé aléatoirement entre les sujets pour éviter tout biais. Pour éviter de nombreux aller-retours et une re-calibration avant chaque passage, les séquences dans le casque et dans le CAVE étaient groupées: le sujet pouvait commencer aléatoirement par le casque ou par le CAVE, puis les modalités pour chaque équipement étaient vécues dans un ordre aléatoire. La différence entre chaque modalité pour le casque comme le CAVE était la quantité de latence globale par rapport au tracking des mouvements de la tête (d'où la manière de déplacer le réticule).
	
	\par Les deux premières modalité de latence sont évidemment, pour le CAVE et pour le casque, le fonctionnement à leur latence nominale. On ajoute ensuite, pour chacun des deux moyens immersifs, un offset de $60~ms$ de latence. La quantité de latence ajoutée a été choisie en fonction de la littérature, pour être au dessus du seuil de perception et ainsi s'assurer une influence de la latence sur les sujets. Les techniques déployées pour ajouter artificiellement de la latence sont décrites dans une section suivante (Paragraphe \ref{sec:ajout_latence_artificielle}). Les deux dernières modalité de latence sont pour le casque de Réalité Virtuelle: sa latence nominale étant bien moins élevée que celle du CAVE, on peut donc le <<~ralentir~>> jusqu'à atteindre les latences nominale et après ajout de latence du CAVE. On se retrouve donc avec 6 expériences différentes de latence (Tab. \ref{tab:latence_casque_cave_expe}).
	
	\begin{table}[h]	
		\centering
		\caption{Mesures de latence (en ms) pour le casque et le CAVE.}
		\label{tab:latence_casque_cave_expe}
		\begin{tabular}{c|c|l}
			\textbf{Système} & \textbf{Latence}\\
			CAVE & $160~ms$ & latence nominale\\
			CAVE & $220~ms$ & latence dégradée\\
			Oculus Rift & $45~ms$ & latence nominale\\
			Oculus Rift & $105~ms$ & latence dégradée\\
			Oculus Rift & $160~ms$ & latence niveau nominal du CAVE\\
			Oculus Rift & $220~ms$ & latence niveau dégradé du CAVE\\
		\end{tabular}
	\end{table}
	
	\par Il aura été nécessaire de faire des mesures préliminaires pour déterminer les latences nominales de nos deux système ainsi que vérifier les valeurs des offsets ajoutés. Ces mesures et la méthode mise en œuvre (inspirée des techniques vues précédemment) sont détaillées plus bas (Paragraphe \ref{sec:mesures_prelim_latence}).
	
	\subsection{Mesures}
	\par Tout au long du passage d'un sujet, un certain nombre de paramètres sont mesurés ou relevés. Certains de manière complètement transparente vis à vis du sujet et donc à priori objectives, d'autres via des questionnaires remplis au fur et à mesure de la session. C'est sur la base de ces données que l'on pourra mener des études statistiques.
	
	\par Le premier type de mesure concerne le temps global mis pour toucher l'ensemble des cibles, l'ordre des cibles, le temps par cible, et enfin, la précision relative en valeur absolue de la visée. Cette dernière est découpée selon l'axe horizontal (x) et l'axe vertical (y) (voir Fig. \ref{fig:x_y_precision_latency}) et est calculée en valeur absolue de manière relative à la taille de la cible: si le sujet arrive à viser précisément le centre de la cible, il obtiendra un résultat de (0,0) alors que s'il vise dans un des angles il obtiendra un résultat de 1 sur les deux axes.
	
	\begin{figure}
		\centering
		\includegraphics[scale=.65]{Figures/XYPrecision}
		\caption{Précisions en X et Y pour l'expérimentation sur la latence.}{Le point rouge correspond au centre théorique de la cible à viser (ici le rétroviseur gauche) tandis que le point vert représente le point réel que le sujet a visé.}
		\label{fig:x_y_precision_latency}
	\end{figure}
	
	\par Le sujet est également amené à remplir des questionnaires tout au long de l'expérimentation, avec notamment les questionnaires de propension à l'immersion \citep{witmer_measuring_1998}, de présence \citep{witmer_measuring_1998} et de mal du simulateur de Kennedy (SSQ). Avant de commencer l'expérimentation, tous les sujets commencent par un questionnaire de propension à l'immersion et un questionnaire de mal du simulateur, pour établir leur état <<~initial~>>. Après chaque passage dans le casque ou dans le CAVE, les sujets doivent remplir à nouveau un questionnaire de mal du simulateur. Après la meilleure condition (c'est à dire celle qui propose la latence la plus basse, la condition nominale) dans le casque, les sujets remplissent un questionnaire de présence. De même pour le CAVE. Les questionnaires utilisés étant originellement en anglais, on utilise les versions traduites en français et vérifiées par \cite{bouchard_revising_2007, bouchard_side_2009, bouchard_exploring_2011}. Ces derniers sont disponibles en annexes.
	
	\par Les questionnaires sont sous-divisés en catégories qui ne nous sont pas toutes utiles. Le questionnaire de cyber-malaise (SSQ) comporte les axes <<~nausée~>> et <<~oculomoteur~>>, que l'on conserve tous les deux car on ne se concentre pas sur un type spécifique de mal du simulateur.
	
	\par Le questionnaire de propension à l'immersion (ITQ) est divisé en 4 axes: <<~focus~>>, <<~implication~>>, <<~émotions~>> et <<~jeu~>>. On ne conserve que les questions liées aux deux premiers axes car les suivants ne sont pas cohérents avec notre expérimentation.
	
	\par Enfin, le questionnaire de présence (PQ) est divisé en 7 axes, dont deux optionnels (que l'on marquera d'une astérisque *): <<~réalisme~>>, <<~possibilité d'agir~>>, <<~qualité de l'interface~>>, <<~possibilité d'examiner~>>, <<~auto-évaluation de la performance~>>, et <<~auditif*~>>, <<~haptique*~>>. Encore une fois, on ne garde que les axes cohérents avec l'expérimentation avec notamment ceux sur le réalisme, la possibilité d'agir et l'auto-évaluation de la performance.
		
	\section{Ajout de latence artificielle}
	\label{sec:ajout_latence_artificielle}
	\par L'ajout de latence artificielle a été déployé de deux manières différentes, pour le casque et le CAVE. Cet écart vient des logiciels utilisés pour afficher l'image dans le CAVE. Un logiciel tierce est employé pour transformer et multiplier les points du vue (un par face du simulateur), logiciel qui recrée sa propre arborescence et son propre système de caméra tandis que l'affichage dans le casque pouvait se faire de manière plus directe avec nos propres paramètres.
	
	\subsection{Dans le casque}
	\par On utilise le SDK de SteamVR pour afficher notre environnement 3D dans le casque de Réalité Virtuelle. Celui-ci utilise des scripts qui à la fois récupèrent les données issues des capteurs (pour suivre le mouvement de la tête) et à la fois calculent les pyramides de vision et la déformation de l'image pour être amenée aux yeux à travers les lentilles. Nous avons essayé dans un premier temps de modifier directement le script de position en y insérant une temporisation entre le moment où les informations des capteurs sont prises, et le moment où elles sont appliquées. Cette méthode ne donnant pas de résultats, nous avons du contourner le problème.
	
	\par Nous avons donc créé une seconde caméra, paramétrée de manière à pouvoir afficher dans le casque, mais dont la position n'est pas mise à jour avec les informations des capteurs. En lieu et place, nous avons créé notre propre script qui prend la position et la rotation dans l'espace de la première caméra, stocke le tout pendant un temps que l'on spécifie, après quoi il applique ces données à la seconde caméra. En parallèle, on force la seconde caméra à s'afficher par dessus la première en permanence. On a donc la caméra originelle qui remplit son travail de récupération des informations des capteurs et qui suit parfaitement les mouvements de l'utilisateur mais qui n'est pas affichée, et une deuxième caméra dont on voit les images et qui calque son mouvement, avec du retard, sur la première caméra.
	
	% Figure caméra suiveuse
	
	\par Cette technique nous laisse la plus grande liberté quant au temps maximal de latence que l'on veut ajouter mais est limitée en précision par le frame rate de l'application: la récupération des informations se fait à chaque calcul d'une nouvelle image. Dans notre cas, l'application tournant à 90 images par seconde, l'imprécision moyenne était donc d'une demi-frame, soit $5~ms$. Au regard des valeurs de latence que l'on ajoute, cela implique un pourcentage d'erreur inférieur à 10\% dans la situation la plus critique.
	
	\subsection{Dans le CAVE}	
	\par Dans le cas du CAVE, la captation des mouvements de l'utilisateur se fait avec un logiciel extérieur (Dtrack 2, de A.R.T.) qui communique ensuite ses données à l'application qui transpose notre simulation en affichage immersif (MiddleVR). Dtrack permet, via des filtres, une anticipation des mouvements qui sont trackés. Si l'on peut régler la puissance de l'anticipation, on peut également lui donner des valeurs négatives, créant ainsi du retard dans les transmissions des données de position et de rotation. C'est cette méthode que l'on utilise dans le CAVE pour générer de la latence artificielle.
	
	% Figure filtre
	
	\section{Mesures préliminaires}
	\label{sec:mesures_prelim_latence}
	\par Une fois les techniques d'ajout de latence déployées, nous avons mis en œuvre, en nous inspirant de ce qui avait été fait dans la littérature et qui a été présenté précédemment, une technique pour mesurer la latence de nos systèmes de Réalité Virtuelle, en condition d'expérimentation. Cette dernière n'étant de nature psychophysique pure et ne visant pas à déterminer très précisément des seuils, nous nous accommodons d'une technique <<~moins~>> précise qu'une technique à l'oscilloscope.
	
	\par Nous avons donc opté pour un procédé filmé à grande vitesse. La mesure de la latence se faisant ensuite en analysant la vidéo image par image pour déterminer l'écart entre le début d'un mouvement et sa prise en compte et son affichage par le logiciel. On filme à 120 images par seconde avec un smartphone.
	
	\par L'objectif est donc de mesurer la latence tout en restant dans les même conditions que celles de l'expérimentation. On place donc un objet (un plan) dans l'habitacle de la voiture qui sera chargé d'afficher les variations de l'objet tracké: les lunettes de stéréoscopie pour le CAVE et le masque entier pour le casque. Ce plan se colore en vert lorsqu'il détecte que le mouvement de l'objet tracké est ascendant (c'est à dire lorsque la coordonnée sur l'axe vertical de l'objet tracké supérieure à sa valeur de l'image précédente), et se colore en rouge lorsqu'il détecte l'inverse.
	
	\par On demande ensuite à une personne d'imprimer verticalement un mouvement sinusoïdal à l'objet tracké et on filme, avec, dans le plan, l'objet bougé et le plan changeant de couleur. On peut donc déterminer visuellement quand est ce que l'opérateur commence un mouvement ascendant ou descendant, puis compter le nombre d'image de la vidéo jusqu'au changement de couleur du plan, signifiant la prise en compte du changement. Plus le nombre d'images entre les deux marqueurs est grand, plus la latence est importante: il s'écoule $8~ms$ entre chaque image de la vidéo. On peut donc mesurer facilement la latence de nos outils, avec une précision d'une demi-image, soit $4~ms$.
	
	\par Les résultats de nos mesures sont synthétisés en Table \ref{tab:latence_casque_cave_expe}. On peut donc ainsi débuter une campagne de mesure sur des sujets, dont les résultats sont développés dans le chapitre suivant.
	
	\begin{figure}
		\centering
		\includegraphics[scale=.8]{Figures/LatencyMeasureTechnique}
		\caption{Technique de mesure de la latence.}{On compte le nombre d'image de la vidéo ralentie entre le début du mouvement (ici, vertical ascendant) et la prise en compte du mouvement par le logiciel, signalée par le passage d'une texture du rouge au vert.}
		\label{fig:mesure_latence_video}
	\end{figure}
	
\chapter{Résultats}
	\par Pour notre expérimentation, nous avons réuni 32 sujets, 17 hommes et 15 femmes. 2 sujets parmi les hommes n'ont pas vu leur résultats retenus pour différentes raisons: l'un n'a pas pu faire tous les segments proposés (mal du simulateur trop élevé) tandis que l'autre fermait les yeux pour contrer ce même mal du simulateur. On termine donc avec 30 sujets ayant des données exploitables, à parité homme femme parfaite. Les sujets étaient âgés de 23 à 54 ans, avec un âge moyen de $31$ ans (écart-type: $\sigma = 11$ ans).

	% Figure population
	
	\section{Dans le CAVE}
	\par The immersion tendency questionnaire (Fig. \ref{fig:itq_pq}) gave back an average value of $44.58$ out of $70$ (standard-deviation: $\sigma = 8.81$) while the presence questionnaire had an average response value of $68.92$ out of $91$ (sd: $\sigma = 10.96$). The initial simulator sickness questionnaire (SSQ) returned an average value of $3.58$ out of $48$ (sd: $\sigma = 3.01$) while the non-latency-degraded setup returned an average of $2.75$ (sd: $\sigma = 2.01$) and the latency-degraded-setup returned $6.08$ (sd: $\sigma = 6.42$).

	\begin{figure}
		\centering
		\includegraphics[width=0.8\linewidth]{Figures/ITQvPQ.png}
		\caption{Comparison of the Immersive Tendency Questionnaire and the Presence Questionnaire for all 12 subjects.}
		\label{fig:itq_pq}
	\end{figure}

	\par The aiming precision is calculated as the average precision on an axis for all targets (i.e. all 24 trials). For the non-latency-degraded setup (Fig. \ref{fig:precision}), the x-axis relative precision of the subjects shooting on targets was  $0.19$ (sd: $\sigma = 0.06$) and, equally, $0.19$ for the y-axis relative precision (sd: $\sigma = 0.09$). The average completion time was $96.79$ seconds (sd: $\sigma = 12.46$). The time per target was evaluated at a mean of $4.03$ seconds (sd: $\sigma = 0.52$).

	\par On the second setup, latency-degraded (Fig. \ref{fig:precision}), the x-axis relative precision of the subjects shooting on targets was  $0.24$ (sd: $\sigma = 0.06$) and $0.20$ for the y-axis relative precision (sd: $\sigma = 0.09$). The average completion time (Fig. \ref{fig:completion_time}) was $121.78$ seconds (sd: $\sigma = 17.07$). The time per target was evaluated at a mean of $5.07$ seconds (sd: $\sigma = 0.71$).

	\begin{figure}
		\centering
		\includegraphics[width=0.8\linewidth]{Figures/CompletionTime.png}
		\caption{Mean values and standard deviations of the completion times for both setups.}
		\label{fig:completion_time}
	\end{figure}

	\par Most of the statistical tests were done using the Welch two sample t-test. The alternative hypothesis was "less". The significance threshold was set at $\alpha = 0.05$. The Welch test was used to determine whether the latency conditions had influence on the precision of the subjects on the x-axis, the y-axis, on the total completion time, the time per target and the variation of the simulator sickness questionnaire results (Tab. \ref{tab:pvalues_ttest}). In addition, a Pearson correlation test was used to explore the relationship between the immersion tendency questionnaire results and the presence questionnaire results.

	\par The immersion tendency versus presence test has a p-value of $p = 0.280$ and a correlation factor of $\rho = 0.340$. The statistical test between the two simulator sickness questionnaires returns a p-value of $p = 0.0620$.

	\par The Welch tests on the influence of comparison between the x-axis precision at lower latency setup and higher latency setup returns a p-value of $p < 0.05$ while the one on the y-axis aiming precision returns a p-value of $p = 0.395$, the one on the completion time returns a p-value of $p < 0.001$ and the last one, on time per target, returns a p-value of $p < 0.001$.

	\begin{table}[h]
		\centering
		\caption{p-values of the Welch two sample t-tests (alternative "less").}
		\label{tab:pvalues_ttest}
		\small
		\begin{tabular}{ccc}
			\multicolumn{1}{l}{\bfseries Response variable} & \multicolumn{1}{c}{\bfseries Degrees of freedom} & \multicolumn{1}{c}{\bfseries p-value}\\
			x-axis precision & 22 & 0.0378\\
			y-axis precision & 22 & 0.395\\
			completion time & 20 & 0.0004\\
			time per target & 20 & 0.0004\\
			SSQ value & 13 & 0.0620\\
		\end{tabular}
	\end{table}
	
	\par Our results show a statistical influence of the latency on the accuracy. When the increase of latency happend, the subjects were 26\% more inaccurate on the lateral movements and 5\% less accurate on the vertical movements. The inequality between the two axes could be explained by the greater movement amplitude needed to reach the left and right targets (left and right mirrors, between 40 et 60 degrees) compared to the amplitude needed to reach the top and bottom targets (central mirror and central display, 15 degrees). A larger movement means a longer interaction time with the latency and hence a higher imprecision.

	\par Another great parameter that must be taken into account is the fast completion of the 24-targets routine that was asked. Keeping a high pace during the experiment implies less care given to to accuracy of the aiming. Hence, our results show a poorer accuracy compared to what could have been reached whether the order would have been to simply aim at the center of the targets. The average accuracy of the subjects above the median of completion time (in the higher latency setup) is greater than the average accuracy of the subjects below the completion time median: $0.26$ against $0.21$ on the horizontal axis and $0.23$ against $0.16$ on the vertical axis. Hence, as well as the interaction time, a higher pace under higher latency condition leads to a higher imprecision. 

	\par Our results also show a statistical influence of latency on the global completion time (with an increase of 26\% over the degraded setup) and the time per target, which is directly linked. Finally, we can observe a large increase of the SSQ values between the two setups (+121\%). However, the statistical significance is just above the threshold showing a weak correlation. This can be explained by the average SSQ degraded setup value being bumped by very high sickness values from a few subjects. On top of the classic vergence-accommodation conflict that causes sickening, there is an other conflict that contributes here to the increase of simulator sickness: the visio-vestibular conflict. The more latency, the more disparity between vision and consciousness of the movement by the vestibular system and hence sickness.
	
	\section{Dans le casque}
	\par qsd
	
	\section{Analyse croisée}
	\par Unfortunatly, we were not able to predict the presence feeling based on the immersive tendency questionnaire answers. The statistical correlation between the two could not be demonstrated. However, this may be heavily resting on the system's specifications.

	\par The more speed in the head movements, the more latency influences user experience ; both in accuracy degradation and in simulator sickness increase. The subjects were facing a choice: either they would slown down their movements to achieve better first intention target aiming or they would keep a good  pace to the detriment of accuracy and sickness. The subjects seem to develop their own strategy to counter the offset of latency, based on how heavily they were burdened by latency. As a result, to ensure the best user experience and the minimize the effect of sickening, it might be advised to suggest slow and small movements to the daily users of the immersives techniques.
	
	\section{Apport au score de réalisme}
	\par qsd
