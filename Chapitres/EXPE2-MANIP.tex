\chapter{Contexte}
	\par Dans ce chapitre, on aborde toute les notions préliminaires à un travail expérimental: la définition du sujet, les valeurs clefs, les méthodes de mesure. On établira également les objectifs que l'on cherchera à atteindre via expérimentation.
	
	\section{Définition et mesure de ses effets}
	\subsection{Définitions}	
	\par Il existe un certain nombre de définitions différentes de la latence. On a présenté notre approche dans la partie sur le score de réalisme. Indépendamment, les auteurs donnent souvent des définitions multiples. On présente ici deux définitions plutôt classiques de la latence (ou plutôt <<~des~>> latences) ainsi qu'une définition plus originale.
	
	\par La première définition est quadruple \citep{papadakis_system_2011}. La latence peut donc être définie telle que:
	\begin{itemize}
		\item le retard entre l'action d'un utilisateur et sa prise en compte par le système,
		\item le temps de calcul lié à l'application, typiquement la lourdeur des graphismes à afficher ou des algorithmes qui travaillent en arrière plan.
		\item le retard du au temps mis pour afficher l'image calculée, qui est au minimum égal au taux de rafraichissement de l'écran,
		\item le retard engendré par la non-synchronisation écran - unité de calcul: une image calculée doit attendre le prochain rafraichissement de l'écran pour être affichée.
	\end{itemize}		
	
	\par D'autres auteurs, \citep{hale_handbook_2015}, proposent quand à eux une version différente, plus adaptée à la Réalité Virtuelle et à l'immersion:
	\begin{itemize}
		\item le retard entre un mouvement de l'utilisateur et la réponse du système de tracking (typiquement, l'envoie de l'information de la nouvelle position à l'ordinateur),
		\item le retard entre le mouvement de l'utilisateur et le même mouvement dans le programme,
		\item de manière générale, un temps de réponse retardé.
	\end{itemize}		
	
	\par On s'aperçoit que si la première définition est sensiblement la même que pour les auteurs précédents, les autres définitions ne convergent pas du tout. Il nous faut donc impérativement clairement définir le concept de latence que l'on utilise pour notre expérimentation. En l'occurrence, on choisit de se mettre dans le cadre deux la deuxième définition de \citep{hale_handbook_2015}: le retard entre le mouvement réel et le mouvement dans la simulation.
	
	\par Enfin, \citep{watson_effects_1998}, parle quant non pas de latence directement mais d'un concept plus global: la réactivité du système, c'est à dire du temps qui s'écoule, lorsque l'on effectue une action, pour recevoir un feedback. La réactivité du système se compose des éléments suivants: la latence en elle-même (sans plus de définition), le temps entre deux images affichées (l'inverse du taux de rafraichissement donc) ainsi que le délai entre l'action de l'utilisateur et le moment suivant où le système vérifie les inputs. Typiquement, si le système de tracking capture les mouvements toutes les $100~ms$ mais que l'utilisateur commence son mouvement $20~ms$ après une capture, il y aura donc automatiquement un délai de $80~ms$	qui s'ajoutera, indépendamment du reste du système.
	
	\subsection{La performance comme outil de mesure}
	\par De nombreux auteurs ont travaillé sur l'influence de la latence. Afin de s'extraire le plus possible de la subjectivité humaine, il fallait trouver une méthode qui ne se repose sur aucun questionnaire, source de biais. L'approche utilisée est alors la performance à l'échelle d'une tâche à réaliser dans l'environnement virtuel. L'influence de la latence sur la performance a été traitée de nombreuse fois dans la littérature \citep{ellis_sensor_1999,mania_perceptual_2004,watson_effects_1998,papadakis_system_2011,meehan_effect_2003}. C'est par ce biais là que nous mèneront également notre expérimentation.
	
	\par Parallèlement, \citep{meehan_effect_2003} proposent un autre moyen d'établir l'influence de la latence, qui ne passe pas par la performance. Pour rester sur des facteurs objectifs, ils mesurent des facteurs biologiques dans le corps humain directement, tels que le rythme cardiaque et la conductance de la peau (qui augmente avec la transpiration). Avec ces mesures, ils démontrent également, de manière alternative là encore, que la latence a un effet sur la présence: plus la latence est faible, plus la présence est forte.
	
	\section{Perception de la latence}
	\subsection{Notions de psychométrie}
	\par L'étude de la littérature nécessite, au préalable, un petit détour par le domaine de la psychométrie et la définition d'un certain nombre de grandeurs que l'on sera amené à rencontrer. On se contentera ici d'une brève introduction pour la compréhension puisque les méthodes de psychométrie ne seront pas utilisées dans cette expérimentation. Les ouvrages de référence restent le Manuel Pratique de Psychophysique de \citep{bonnet_manuel_1986} pour la langue française et Psychophysics: A Practical Introduction de \citep{kingdom_psychophysics:_2010} pour la langue anglaise.
	
	\par La psychométrie est l'étude quantitative de la relation entre un phénomène physique quantifiable et la ou les réponses générées par le système sensoriel humain. Elle permet d'établir des modèles de fonctionnement à plusieurs niveaux: la structure du stimulus, le fonctionnement perceptif, ou bien le/s processus d'élaboration des réponses sensorielles. La notion de stimulus est ainsi définie \citep{bonnet_manuel_1986}:
	\begin{quote}
		Ensemble des évènements physiques qui déclenchent l'activité des récepteurs sensoriels et étant ainsi à l'origine des réponses observées.
	\end{quote}
	
	\par Une notion fondamentale en psychométrie est celle de seuil, c'est à dire de limite établie entre deux états: l'état haut et l'état bas. Selon la tâche effectuée, l'état haut peut être une détection de stimulus, une discrimination, une reconnaissance, une identification, ... tandis que l'état bas sera toujours défini comme l'absence d'état haut. Trois hypothèses sont nécessaires à la reconnaissance d'un seuil:
	\begin{itemize}
		\item \textbf{Hypothèse 1:} il ne doit pas être attribué au stimulus de part dans la variation observée des réponses (c'est à dire que le stimulus est considéré comme parfait et le récepteur comme observant des lois de probabilité),
		\item \textbf{Hypothèse 2:} il est admis un continuum des états d'excitation en réponse (c'est à dire que le comportement du système sensoriel ne doit pas changer du tout au tout au passage du seuil),
		\item \textbf{Hypothèse 3:} il est admis l'existence d'un mécanisme de réponse qui peut être modélisé sous la forme d'une règle logique.
	\end{itemize}		
	
	\par On note plus particulièrement deux seuils caractéristiques qui nous intéressent: le seuil de détection et le seuil de discrimination. 
	
	\par Le premier, appelé seuil de détection ou <<~absolute threshold~>> en anglais, caractérise la détection du stimulus, c'est à dire la capacité du sujet à répondre sur la présence ou l'absence de ce dernier. Il est nécessaire mais non suffisant pour déterminer en entier un système sensoriel: il faudrait également pouvoir estimer la limite supérieure. Cependant, et dans de nombreux cas, il est difficile de mesurer expérimentalement au delà d'une certaine intensité de stimulus sans endommager le système sensoriel des sujets. Typiquement, une luminance trop forte détruirait les cellules de la rétine dans l'œil. Ces grandeurs dont on ne peut pas mesurer le seuil maximal sont appelées <<~métathétique~>> \citep{stevens_psychophysical_1957}.
	
	\par Le deuxième seuil caractéristique est celui de discrimination (ou JND en anglais pour <<~just noticeable difference~>>). Il quantifie la capacité du sujet à distinguer une présence ou une absence de différence entre deux stimuli. Tout système, physique ou biologique, peut être caractérisé d'une part par ses limites de fonctionnement mais aussi par son pouvoir de résolution, sa capacité à discriminer deux niveaux voisins de signaux qu'il traite.
	
	\par La psychométrie propose ensuite des paradigmes pour établir des protocoles expérimentaux et des méthodes pour traiter les résultats et en extraire des modèles (avec notamment l'usage des fonctions psychométriques). Néanmoins, nous n'avons pas eu recours à ces méthodes pendant nos expérimentations et le développer serait donc légèrement hors-cadre. On présente donc dans la section suivante les différents seuils et influences sur l'expérience utilisateur liés à la latence, dans la littérature.	
	
	\subsection{Dans la littérature}
	\par Il est tout d'abord à noter que la perception de la latence se ferait de manière indirecte \citep{adelstein_head_2003}: elle serait perçue non pas directement pas les systèmes sensoriels mais par son effet sur l'environnement. On parle alors d' <<~oscillopsie~>> \citep{allison_tolerance_2001}, c'est à dire que l'environnement semble bouger, flotter dans l'espace. On peut donc extrapoler que, plus l'environnement est immersif, plus la ressenti de la latence sera fort. La perception est également indépendante de la complexité de la scène \citep{mania_perceptual_2004}: que l'on soit dans un décors minimaliste avec quelques polygones ou une scène surchargée (fig ?), si les deux ont la même quantité de latence, le ressenti sera le même. Enfin, la latence ne suivrait pas la loi de Weber \citep{adelstein_head_2003} qui implique que le seuil de perception est proportionnel à la valeur de l'intensité du stimulus: on percevrai donc également la même variation de latence, quelle que soit la valeur initiale de celle-ci.
	
	\par Le seuil de perception, donc de capacité à dire si le stimulus est présent ou non, a été mesuré à hauteur d'un intervalle de $15$ à $18.6~ms$ \citep{regan_real-time_1999}. Néanmoins, ces valeurs ont été observées pour un environnement souvent non-immersif et, comme on l'a vu au paragraphe précédent, ce dernier paramètre pourrait avoir une forte influence sur le résultat. De même, les résultats peuvent fortement varier suivant si la tâche demandée pendant l'expérimentation demande de se concentrer sur la perception de la latence ou de se concentrer sur une autre activité. Par ailleurs, \citep{brooks_whats_1999} estime le seuil de perception, pour les simulateurs de vol, à une valeur de $50~ms$. Regan et al. estiment également que le lag spécifiquement imputable au calcul de l'image (sans prise en compte ni de l'acquisition du mouvement, ni de l'affichage) est perceptible à partir de $15 \pm 3~ms$.
	
	\par Le seuil de discrimination (capacité à distinguer une différence entre deux stimuli) quant à lui, est mesuré pour la main à une valeur comprise entre $15$ et $20~ms$ et monte à une valeur de $50~ms$ pour la tête \citep{ellis_sensor_1999}. De leur côté, \citep{adelstein_head_2003} et \citep{mania_perceptual_2004} proposent des valeurs pour le tracking de la tête plus proches des valeurs de Ellis pour le tracking de la main avec respectivement $13.6 \pm 0.6~ms$ ($Max = 24.6~ms$) et $9.1 \pm 1.6~ms$ de JND.
	
	\par Enfin, \citep{allison_tolerance_2001} font une remarque intéressante: plus le mouvement de la tête est rapide, plus la latence doit être faible. Ils proposent des valeurs assez élevées comme seuil de perception mais l'ordre de grandeur permet toutefois la comparaison: pour une rotation lente de la tête, une latence de $320~ms$ est acceptable, tandis que pour une rotation rapide, le seuil descend à $180~ms$. Ces valeurs correspondent bien à la théorie de perception indirecte de la latence: plus on bouge vite, plus l'environnement va <<~flotter~>> et donc plus la perception sera forte. Cela donne également des indices sur une stratégie à adopter: quand la latence augmente, il peut être bienvenu de ralentir ses mouvements.
	
	\section{Mesure de la latence}
	\par On a vu que la mesure de l'influence de la latence sur l'être humain se faisait généralement via un indice de performance sur une tâche donnée. Il faut également être capable de mesurer le plus précisément possible quelle est le niveau de latence auquel la tâche s'effectue. Cette fois, la mesure ne peut être qu'objective puisqu'elle n'implique pas le sujet humain mais seulement le système directement. On trouve un certain nombre de techniques dans la littérature, que nous allons présenter brièvement ici (de manière non exhaustive).
	
	\par Une première méthode pour déterminer la latence d'un système est décrite chez  \citep{liang_temporal-spatial_1991} et implique l'utilisation d'un pendule, d'un pendule fixe, d'une caméra, d'un module de tracking (ici, <<~Isotrack~>>) et d'un écran de retour (Fig. \ref{fig:liang_pendulum}). La technique revient à faire osciller un pendule devant une base fixée verticalement (type fil à plomb). Un système de tracking est associé au pendule et affiche, via l'écran de retour, ses mesures horodatées de position du pendule. Avec une caméra placée dans l'axe des pendules on peut, en analysant la vidéo image par image, on peut mesurer l'écart de temps entre la mesure indiquant que le pendule est alignée avec la référence et l'image montrant effectivement l'alignement entre les deux.
	
	\begin{figure}
		\centering
		\includegraphics[scale=.75]{Figures/LiangPendulum}
		\caption{Méthode du pendule pour le calcul de la latence.}{Image tirée de \citep{liang_temporal-spatial_1991}}
		\label{fig:liang_pendulum}
	\end{figure}
	
	\par \citep{jacoby_improved_1996} utilisent également un pendule mais sans traitement vidéo a posteriori qui peut être un facteur d'imprécisions si la fréquence de capture d'image est trop basse (on risque de ne pas avoir l'image qui montre l'alignement parfait mais celle avec quelques degrés de plus ou de moins). Dans ce protocole, un ordinateur affiche une scène d'environ 1000 polygones non texturés et est relié à un système émetteur-receveur infrarouge. Le pendule coupe le rayon infrarouge à un certain point de sa course, ce qui a pour effet d'envoyer un ordre vers l'ordinateur qui doit modifier la couleur de certains de ces polygones. Un photodétecteur surveille en permanence l'écran et envoie un signal en tension lorsqu'il détecte le changement de couleur sur l'écran. Le système infrarouge et le photodétecteur sont tous deux cablés sur un oscilloscope qui permet de mesurer avec précision le temps entre leurs signaux respectifs.
	
	\par Il existe d'autres techniques mises au point qui n'impliquent pas de pendule et de mouvement oscillatoire. \citep{swindells_system_2000} génèrent un mouvement cyclique et périodique à l'aide de la table tournante d'un lecteur de vinyles. Un disque tracké est placé sur la table tournante et son mouvement est reproduit dans une scène virtuelle (Fig. \ref{fig:swindells_phonograph}). L'écart angulaire est mesuré entre le disque réel et le disque virtuel via des prises photo ou vidéo. La vitesse de rotation étant fixée et donc connue, on peut alors en déduire le temps de latence généré par le système.
	
	\begin{figure}
		\centering
		\includegraphics[scale=.75]{Figures/SwindellsPhonograph}
		\caption{Méthode de la table tournante pour le calcul de la latence.}{Image tirée de \citep{swindells_system_2000}. La position du disque physique est appliqué au disque dans la scène virtuelle. Les deux images sont superposées et on mesure l'écart angulaire entre les deux. A partir de la vitesse de rotation on peut remonter à la latence.}
		\label{fig:swindells_phonograph}
	\end{figure}
	
	\par \citep{steed_simple_2008} proposent une autre méthode de pendule tracké, annoncée plus simples que les précédentes. Une diode électroluminescente rouge est fixée à un pendule et trackée grâce à un système optique. Le mouvement de la diode rouge est reproduit en vert sur un écran placé derrière le pendule tandis qu'une caméra filme l'ensemble. A partir de la vidéo, on peut être en mesure de reproduire les sinusoïdes qui décrivent les mouvements des diodes réelles et virtuelles et ainsi en déduire la latence du système en prenant le temps crête à crête.
	
	\par Si les méthodes décrites jusqu'à présent sont très abstraites par rapport au déroulement réel d'une application en VR, \citep{di_luca_new_2010} proposent une technique applicable à plusieurs objets, que ce soit des lunettes 3D, un objet quelconque ou un casque de Réalité Virtuelle. La méthode nécessite deux photodétecteurs: le premier placé sur l'objet à tracker et le second au niveau de l'écran qui servira à afficher l'image pour le sujet: dans la cas d'un casque, les deux photorécepteurs seront placés sur le même objet (mais à des positions différents) alors que dans le cas d'un CAVE, les photorécepteurs seront distants. On affiche dans la direction du premier photorécepteur (celui sur l'objet tracké) un gradient lumineux (un dégradé du noir vers le blanc typiquement) fixe. Si on déplace l'objet tracké dans le sens du gradient, on pourra obtenir l'équivalent de sa <<~position~>> via sa valeur de luminosité capturée. De l'autre côté, le deuxième photodétecteur est dirigé vers l'écran destiné à l'utilisateur sur lequel on affiche une nuance de gris (uniforme sur tout l'écran) en fonction des informations de tracking que l'on reçoit. En comparant le temps auquel le photorécepteur passe devant une nuance de gris donnée et le temps où l'écran final affiche cette nuance de gris, on obtient la latence globale du système.
	
	\begin{figure}
		\centering
		\includegraphics[scale=.65]{Figures/DiLucaGradient}
		\caption{Méthode des gradients pour le calcul de la latence.}{Le cadre rouge représente la zone réellement mesurée par le photorécepteur tandis que le grand cadre vert montre la couleur affichée par l'écran final, ce qui correspond à une <<~position~>> sur le gradient fixe représentée par le cadre vert en pointillés. La différence entre les deux petits cadres permet de calculer la latence du système.}
		\label{fig:di_luca_gradient}
	\end{figure}
	
	\par Néanmoins, les méthodes impliquant des pendules ont un défaut majeur: les 6 axes de mouvements sont autorisés, ce qui donne un mouvement avec une composante fondamentale ainsi que de petites composantes qui peuvent influer sur le résultat final en raison de la petite quantité parcourue supérieure par rapport à la théorie. \citep{papadakis_system_2011} proposent donc une méthode similaire au plateau tournant, avec un un système limité à 3 degrés de liberté dont 2 fixés. Une rotation est donc générée avec un servo-moteur et contrôlée avec un encodeur, le tout relié à un oscilloscope. L'environnement virtuel lisant les valeurs de l'encodeur est programmé de telle manière que, lorsque certains seuils de rotation sont franchis, il affiche un changement graphique (un carré de couleur blanche devient noir et inversement). Une photodiode placée au niveau de l'écran surveille ce carré et renvoie un signal à l'oscilloscope en cas de changement. Le reste de la scène virtuelle est un environnement lourd en polygones (environ 140000) et soumis à des calculs de lumière complexes afin de se rapprocher des usages normaux. On relève enfin la mesure de la latence sur l'oscilloscope avec le temps entre le passage de seuil au niveau de l'encodeur, et le changement de couleur au niveau de la photodiode.
	
	\par Bien que, dans l'idéal et pour maximiser la précision dans les mesures, il faudrait utiliser un oscilloscope, nous utilisons une méthode par la vidéo semblable à celle proposée par \citep{steed_simple_2008}, pour mesurer la latence de nos propres systèmes ; la précision étant suffisante pour notre application (voir chapitre suivant).
	
	
\chapter{Mise en place du dispositif expérimental}
	\par Maintenant que l'on connait mieux le contexte de la latence dans la réalité virtuelle, on décide de mener une expérimentation à ce propos. Si on connait les seuils de perception et de discrimination de la latence, la variation de la performance n'est pas décrite: on sait simplement qu'elle change, mais pas de combien en fonction de l'évolution de la latence. Les objectifs liés à cette expérimentation sont donc multiples:
	
	\begin{itemize}
		\item développer un des critères prépondérant du modèle de score de réalisme,
		\item regarder l'influence de la latence sur la performance, en milieu immersif (et écologique),
		\item comparer entre deux moyens immersifs (un casque et un simulateur type CAVE),
		\item déterminer un seuil au delà duquel l'expérience utilisateur devient trop impactée. 
	\end{itemize}	
	
	\section{Tâche à effectuer}
	\par Les sujets étaient confrontés à une situation écologique, c'est à dire sensée représenter la vie <<~réelle~>>, et il leur était demandé de réaliser une tâche de tous les jours telle que regarder à des endroits précis dans le cockpit d'une voiture, pendant de courts laps de temps.
	
	\subsection{Moyens immersifs}	
	\par Un des objectifs de l'expérimentation étant de faire également une comparaison entre plusieurs moyens immersifs,	on fait passer nos sujets dans un casque de Réalité Virtuelle (un Oculus Rift) et dans un simulateur de type CAVE.
	
	\par Le CAVE est le même que pour les précédentes expérimentations, que ce soit pour le contraste et la luminance que pour la conduite suivie de questionnaires. Les sujets sont donc assis dans un CAVE 4 faces à 1 mètre de distance de la face principale (avant). Les sujets n'étaient pas assis sur un siège de voiture comme dans nos autres expérimentations mais sur un siège normal. Ce changement est dû à plusieurs raisons: aucune tâche de conduite n'était nécessaire, pour garder la continuité avec la chaise utilisée pendant les essais dans le casque, et pour des facilités de manœuvre. Les sujets n'étaient donc équipés que des lunettes de stéréoscopie et d'une manette de jeu faisant office d'interface de contrôle. Du point de vue des performances graphiques, l'application utilisée pendant l'expérimentation tournait à une valeur constante de 60 images par seconde.
	
	\par La partie casque de Réalité Virtuelle s'appuyait sur un Oculus Rift de type CV1 (Commercial Version 1, voir Fig. \ref{fig:oculus_rift}). L'utilisation du casque se faisait assis à une table disposée dans un des coins du CAVE, hors de vue des sujets passant dans le simulateur. L'assise se faisait au moyen d'une chaise parfaitement similaire à la première pour assurer une continuité entre les deux. La caméra de tracking était placée sur la table, cette dernière servant aussi à répondre aux différents questionnaires (voir ensuite). De cette manière, les sujets pouvaient enchainer les deux moyens immersifs sans coupure. En terme de performances, l'application était stabilisée à 90 images par seconde.
	
	\par L'environnement virtuel était commun au CAVE et au casque: le sujet était assis au volant d'une voiture (modèle <<~officiel~>> modélisé par Renault), à l'arrêt dans un <<~paysage~>> constitué de l'intérieur des bâtiments de Renault. Le paysage était réalisé au moyen d'un photo 360 degrés pour un maximum de photo-réalisme et pour limiter le nombre de pixels dans la scène (déjà bien chargée par le modèle de la voiture). Les lumières et réflexions des miroirs étaient pré-calculées pour limiter au maximum l'impact sur le temps de calcul des images.
	
	\begin{figure}
		\centering
		\includegraphics[scale=.65]{Figures/OculusRift}
		\caption{Oculus Rift et ses accessoires.}{De gauche à droite: la caméra permettant de tracker le casque, le casque vu de face (version CV1) et la manette de Xbox associée.}
		\label{fig:oculus_rift}
	\end{figure}
	
	\subsection{Modus operandi}
	\par Precisely, the subjects are immersed in a realistic-looking car and its environment. They were  asked to visually aim at given points in the car, in a random order. The aiming was helped with a game-like virtual reticle follwing the movements of the head. The target to aim were indicated through the mean of a white arrow pointing one out of four possible directions (left, up, right and down). Whenever the subjects assumed to be at the center of the designated target, they would hit a button on a joystick they held in their hands. There were four different possible targets, bounded to the direction of the arrow: the left and right mirrors, the rear view mirror and the central display. The routine was made of 24 targets to hit (6 times each of the 4 targets) presented in a random order. The subjects were asked to replace their gaze at the arrow location after every aiming routine. The software automatically and transparently recorded the hit position on the target (x-axis and y-axis coordinates) and the hit time. The hit position was then used to compute how far from the center of the target the subject shot. The output is relative to the size of the target and thus given between 0 and 1 on both axes.
	
	\begin{figure}
		\centering
		\includegraphics[scale=.9]{Figures/ExpeLatency}
		\caption{Environnement virtuel pour l'expérimentation sur la latence.}{L'image est tirée du point de vue du sujet, la flèche blanche indique la cible à viser (ici, le rétroviseur gauche) tandis que la croix rouge (le viseur) est alignée avec la direction de la tête.}
		\label{fig:apparatus_latency}
	\end{figure}

	\par The same 24 targets aiming routine was performed twice: once at the standard running capability of the immersive system (reference setup) and once in a degraded state of the system, latency-wise. The order was alternated between subjects in order to limit any bias. Latency was added on the tracking of the head. Technically, the tracking is correctly performed but delayed in time. We did not degrade the frame rate to be able to keep a high frame rate and thus a smooth (but late) simulation.

	\par The latency offset we added in our experiment is based on the different values that were presented previously in the Research Question section. In order to stay within the range of the performance interaction threshold, we chose to add an amount of $60~ms$ within the tracking loop of the head (Fig. \ref{fig:added_latency_intheloop}).
	
	\subsection{Mesures}
	\par Tout au long du passage d'un sujet, un certain nombre de paramètres sont mesurés ou relevés. Certains de manière complètement transparente vis à vis du sujet et donc à priori objectives, d'autres via des questionnaires remplis au fur et à mesure de la session. C'est sur la base de ces données que l'on pourra mener des études statistiques.
	
	\par Le première type de mesure concerne: le temps global mis pour toucher l'ensemble des cibles, l'ordre des cibles, le temps par cible, et enfin, la précision relative en valeur absolue de la visée. Cette dernière est découpée selon l'axe horizontal (x) et l'axe vertical (y) (voir Fig. \ref{fig:x_y_precision_latency}) et est calculée de manière relative par rapport à la taille de la cible: si le sujet arrive à viser précisément le centre de la cible, il obtiendra un résultat de (0,0) alors que s'il vise dans un des angles il obtiendra un résultat de 1 sur les deux axes (toutes les mesures sont prises en valeur absolue).
	
	\begin{figure}
		\centering
		\includegraphics[scale=.65]{Figures/XYPrecision}
		\caption{Précisions en X et Y pour l'expérimentation sur la latence.}{Le point rouge correspond au centre théorique de la cible à viser (ici le rétroviseur gauche) tandis que le point vert représente le point réel que le sujet a visé.}
		\label{fig:x_y_precision_latency}
	\end{figure}
	
	\par Le sujet est également amené à remplir des questionnaires tout au long de l'expérimentation, avec notamment les questionnaires de propension à l'immersion \citep{witmer_measuring_1998}, de présence \citep{witmer_measuring_1998} et de mal du simulateur de Kennedy (SSQ). Tous les sujets commencent par un questionnaire de propension à l'immersion et un questionnaire de mal du simulateur, pour établir leur état <<~de base~>>. Après chaque passage dans le casque ou dans le CAVE, les sujets doivent remplir à nouveau un questionnaire de mal du simulateur. Après la meilleure condition (c'est à dire celle qui propose la latence la plus basse) dans le casque, les sujets remplissent un questionnaire de présence. De même pour le CAVE. Les questionnaires utilisés étant en anglais, on utilise les versions traduites et vérifiées par \cite{bouchard_revising_2007, bouchard_side_2009, bouchard_exploring_2011}. Ces derniers sont disponibles en annexes.
	
	\par Les questionnaires sont sous-divisés en catégories qui ne nous sont pas toutes utiles. Le questionnaire de cyber-malaise (SSQ) comporte les axes <<~nausée~>> et <<~oculomoteur~>>, que l'on conserve tous les deux car on ne se concentre pas sur un type spécifique de mal du simulateur.
	
	\par Le questionnaire de propension à l'immersion (ITQ) est divisé en 4 axes: <<~focus~>>, <<~implication~>>, <<~émotions~>> et <<~jeu~>>. On ne conserve que les questions liées aux deux premiers axes car les suivants ne sont pas cohérents avec notre expérimentation.
	
	\par Enfin, le questionnaire de présence (PQ) est divisé en 7 axes, dont deux optionnels (que l'on marquera d'une astérisque *): <<~réalisme~>>, <<~possibilité d'agir~>>, <<~qualité de l'interface~>>, <<~possibilité d'examiner~>>, <<~auto-évaluation de la performance~>>, et <<~auditif*~>>, <<~haptique*~>>. Encore une fois, on ne garde que les axes cohérents avec l'expérimentation avec notamment ceux sur le réalisme, la possibilité d'agir et l'auto-évaluation de la performance.
		
	\section{Ajout de latence artificielle}
	\subsection{Dans le CAVE}	
	\par The addition of latency was made by applying a filter in the tracking software. The filter was set with a negative amount of anticipation time.
	
	\subsection{Dans le casque}
	\par une méthode différente: pourquoi ?
	
	\par la méthode en question
	
	\section{Mesures préliminaires}
	\par In order to properly conduct our experiment, some values needed to be verified upstream. We had to measure the total amount of latency, with and without added latency (and hence verify that the filter is well applied). There exists a lot of different techniques to measure end-to-end latency \cite{papadakis_system_2011}. Since our system tracks the VR glasses, we chose to apply a color tint to the 3D environment, based on the height difference of the tracked device (compared to the height at the previous frame). For a positive difference (actual height greater than previous-frame height) the world was tinted green while for a negative diffrence (actual height smaller than previous-frame height) the world was tinted red. We then applied a sinusoidal vertical movement to the glasses and filmed the output (glasses + screens) at 120~Hz. By running frame by frame the thus obtained video, we could count the number of frames between a real change of direction of the glasses' movement (ascendent or descendent) and its display (which was characterized by a tint change of the 3D environment). The precision is hence half a frame, which means $4~ms$. Our measurements report a total amount of latency of $160~ms$ for the reference system, and a correct addition of $60~ms$ in the tracking loop, which leads to a total amount of latency of $220~ms$ for the degraded setup.
	
\chapter{Résultats}
	\par Pour notre expérimentation, nous avons réuni 32 sujets, 17 hommes et 15 femmes. 2 sujets parmi les hommes n'ont pas vu leur résultats retenus pour différentes raisons: l'un n'a pas pu faire tous les segments proposés tandis que l'autre fermait les yeux pour contrer le mal du simulateur. On termine donc avec 30 sujets ayant des données exploitables, à parité homme femme parfaite. Les sujets étaient âgés de 23 à 54 ans, avec un âge moyen de $31$ ans (écart-type: $\sigma = 11$ ans).

	% Figure population
	
	\section{Dans le CAVE}
	\par qsd
	
	\section{Dans le casque}
	\par qsd
	
	\section{Analyse croisée}
	\par qsd
	
	\section{Apport au score de réalisme}
	\par qsd
